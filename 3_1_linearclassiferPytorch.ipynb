{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "3.1_linearclassiferPytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twinwood/AI-Capstone-Project/blob/main/3_1_linearclassiferPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzkr56eBlqaW"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
        "</a> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnJ0sfLolqaa"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2ctDuEzlqab"
      },
      "source": [
        "<h1>Objective</h1><ul><li> How to use linear classifier in pytorch.</li></ul> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNembAuclqab"
      },
      "source": [
        "<h1>Linear  Classifier with PyTorch </h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UfXIzkelqac"
      },
      "source": [
        "<p>Before you use a  Deep neural network to solve the classification problem,  it 's a good idea to try and solve the problem with the simplest method. You will need the dataset object from the previous section.\n",
        "In this lab, we solve the problem with a linear classifier.\n",
        " You will be asked to determine the maximum accuracy your linear classifier can achieve on the validation data for 5 epochs. We will give some free parameter values if you follow the instructions you will be able to answer the quiz. Just like the other labs there are several steps, but in this lab you will only be quizzed on the final result. </p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7X8GRq8lqac"
      },
      "source": [
        "<h2>Table of Contents</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IywkcWTzlqad"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"#download_data\"> Download data</a></li>\n",
        "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
        "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
        "    <li><a href=\"#trasform_Data_object\">Transform Object and Dataset Object</a></li>\n",
        "    <li><a href=\"#Question\">Question</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>25 min</strong></p>\n",
        " </div>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAynKbfVlqae"
      },
      "source": [
        "<h2 id=\"download_data\">Download Data</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obf8B57blqaf"
      },
      "source": [
        "In this section, you are going to download the data from IBM object storage using <b>wget</b>, then unzip them.  <b>wget</b> is a command the retrieves content from web servers, in this case its a zip file. Locally we store the data in the directory  <b>/resources/data</b> . The <b>-p</b> creates the entire directory tree up to the given directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdLCFwHTlqag"
      },
      "source": [
        "First, we download the file that contains the images, if you dint do this in your first lab uncomment:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKQvgcx0lqah",
        "outputId": "f8ce8b11-6ae1-410a-8f7a-68f74137f4c6"
      },
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip -P /resources/data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-26 07:32:52--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 245259777 (234M) [application/zip]\n",
            "Saving to: ‘/resources/data/concrete_crack_images_for_classification.zip’\n",
            "\n",
            "concrete_crack_imag 100%[===================>] 233.90M  25.5MB/s    in 9.1s    \n",
            "\n",
            "2021-05-26 07:33:02 (25.6 MB/s) - ‘/resources/data/concrete_crack_images_for_classification.zip’ saved [245259777/245259777]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcUfk6T-lqai"
      },
      "source": [
        "We then unzip the file, this ma take a while:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TITMpa3wlqaj"
      },
      "source": [
        "!unzip -q  /resources/data/concrete_crack_images_for_classification.zip -d  /resources/data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9LOpnAElqaj"
      },
      "source": [
        "We then download the files that contain the negative images:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71NY7JpVlqaj"
      },
      "source": [
        "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC0zKSzQlqaj"
      },
      "source": [
        "The following are the libraries we are going to use for this lab:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQbHZn-4lqak"
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch import optim "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQE4PRdqlqak"
      },
      "source": [
        "<h2 id=\"data_class\">Dataset Class</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avas0wj7lqak"
      },
      "source": [
        "In this section, we will use the previous code to build a dataset class. As before, make sure the even samples are positive, and the odd samples are negative.  If the parameter <code>train</code> is set to <code>True</code>, use the first 30 000  samples as training data; otherwise, the remaining samples will be used as validation data. Do not forget to sort your files so they are in the same order.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh4bO_f7lqak"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        directory=\"/resources/data\"\n",
        "        positive=\"Positive\"\n",
        "        negative=\"Negative\"\n",
        "\n",
        "        positive_file_path=os.path.join(directory,positive)\n",
        "        negative_file_path=os.path.join(directory,negative)\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
        "        positive_files.sort()\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
        "        negative_files.sort()\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files \n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "        \n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)    \n",
        "       \n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        \n",
        "        image=Image.open(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "          \n",
        "        \n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V5LdWuwlqak"
      },
      "source": [
        "<h2 id=\"trasform_Data_object\">Transform Object and Dataset Object</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga6ICmh8lqal"
      },
      "source": [
        "Create a transform object, that uses the <code>Compose</code> function. First use the transform <code>ToTensor()</code> and followed by <code>Normalize(mean, std)</code>. The value for <code> mean</code> and <code>std</code> are provided for you.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIUAGkf7lqal"
      },
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "# transforms.ToTensor()\n",
        "#transforms.Normalize(mean, std)\n",
        "#transforms.Compose([])\n",
        "\n",
        "transform =transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std)])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdOYRYE9lqal"
      },
      "source": [
        "Create object for the training data  <code>dataset_train</code> and validation <code>dataset_val</code>. Use the transform object to convert the images to tensors using the transform object:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-GwrRLClqal"
      },
      "source": [
        "dataset_train=Dataset(transform=transform,train=True)\n",
        "dataset_val=Dataset(transform=transform,train=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGp0YuRLlqam"
      },
      "source": [
        "We  can find the shape of the image:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml3k4Bxglqam",
        "outputId": "4fcba79e-d6a0-4f41-f218-abce983f1e69"
      },
      "source": [
        "dataset_train[0][0].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 227, 227])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CnqSEoNlqao"
      },
      "source": [
        "We see that it's a color image with three channels:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2qwC4volqao",
        "outputId": "d3c53c5c-eb92-469d-f239-f1c2fc6f2ca2"
      },
      "source": [
        "size_of_image=3*227*227\n",
        "size_of_image"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPq4rJWKlqap"
      },
      "source": [
        "<h2 id=\"Question\"> Question <h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2UZcXgllqap"
      },
      "source": [
        "<b> Create a custom module for Softmax for two classes,called model. The input size should be the <code>size_of_image</code>, you should record the maximum accuracy achieved on the validation data for the different epochs. For example if the 5 epochs the accuracy was 0.5, 0.2, 0.64,0.77, 0.66 you would select 0.77.</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q04Dpcfllqap"
      },
      "source": [
        "Train the model with the following free parameter values:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7ufdyfDlqap"
      },
      "source": [
        "<b>Parameter Values</b>\n",
        "\n",
        "   <li>learning rate:0.1 </li>\n",
        "   <li>momentum term:0.1 </li>\n",
        "   <li>batch size training:1000</li>\n",
        "   <li>Loss function:Cross Entropy Loss </li>\n",
        "   <li>epochs:5</li>\n",
        "   <li>set: torch.manual_seed(0)</li>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx38xI4qlqap",
        "outputId": "2835e34e-d4f9-4169-ff3a-bbc09a1813b3"
      },
      "source": [
        "learning_rate = 0.1\n",
        "momentum_term = 0.1\n",
        "batch_size = 1000\n",
        "#loss_function:Cross Entropy Loss\n",
        "epochs=5\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5d40dd0b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0-lkbFWlqap"
      },
      "source": [
        "<b>Custom Module:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE_Q-IZVlqap"
      },
      "source": [
        "class SoftMax(nn.Module):\n",
        "    def __init__(self, in_size, output_size):\n",
        "        super(SoftMax, self).__init__()\n",
        "        self.linear=nn.Linear(in_size, output_size)\n",
        "    def forward(self,x):\n",
        "        out= self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOZ-HuFDlqar"
      },
      "source": [
        "<b>Model Object:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDg9jI7clqar"
      },
      "source": [
        "input_dim = 227*227*3\n",
        "output_dim = 2\n",
        "model = SoftMax(in_size=input_dim , output_size=output_dim)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKkna2Sxlqar"
      },
      "source": [
        "<b>Optimizer:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD8TUycVlqar"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = momentum_term)    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivOPBZqglqar"
      },
      "source": [
        "<b>Criterion:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIzGDCSnlqar"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOh7Wq7rlqar"
      },
      "source": [
        "<b>Data Loader Training and Validation:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "119zpSCSlqar"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size )\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXxY6-c4lqas"
      },
      "source": [
        "<b>Train Model with 5 epochs, should take 35 minutes: </b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2WwZmcTlqas",
        "outputId": "2f7fd152-d680-4f54-8349-849b09f15065"
      },
      "source": [
        "print(\"Start Training...\")\n",
        "cost_list=[]\n",
        "accuracy_list=[]\n",
        "N_test=len(dataset_val)\n",
        "n_epochs=5\n",
        "\n",
        "def model_train(n_epochs):\n",
        "    global input_dim\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Training epoch {} ......\".format(epoch))\n",
        "        cost=0\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            z = model(x.view(-1,input_dim))\n",
        "            loss = criterion(z, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            cost+=loss.item()\n",
        "        correct=0\n",
        "        #perform a prediction on the validation  data \n",
        "        for x_test, y_test in test_loader:\n",
        "            z = model(x_test.view(-1,input_dim))\n",
        "            _, yhat = torch.max(z.data, 1)\n",
        "            correct += (yhat == y_test).sum().item()\n",
        "        accuracy = correct / N_test\n",
        "        accuracy_list.append(accuracy)\n",
        "        cost_list.append(cost)\n",
        "        print(\"For Epoch {}, Accuracy is {} \".format(epoch, accuracy_list))\n",
        "\n",
        "model_train(n_epochs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Training...\n",
            "Training epoch 0 ......\n",
            "For Epoch 0, Accuracy is [0.6197] \n",
            "Training epoch 1 ......\n",
            "For Epoch 1, Accuracy is [0.6197, 0.5541] \n",
            "Training epoch 2 ......\n",
            "For Epoch 2, Accuracy is [0.6197, 0.5541, 0.5699] \n",
            "Training epoch 3 ......\n",
            "For Epoch 3, Accuracy is [0.6197, 0.5541, 0.5699, 0.7589] \n",
            "Training epoch 4 ......\n",
            "For Epoch 4, Accuracy is [0.6197, 0.5541, 0.5699, 0.7589, 0.7549] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORofzPqZlqas"
      },
      "source": [
        "#Plot the graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "iyxJD7jFlqat",
        "outputId": "e5d1697c-f253-4176-fbd4-c8481c638d7b"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "color = 'tab:red'\n",
        "ax1.plot(cost_list, color=color)\n",
        "ax1.set_xlabel('epoch', color=color)\n",
        "ax1.set_ylabel('Cost', color=color)\n",
        "ax1.tick_params(axis='y', color=color)\n",
        "    \n",
        "ax2 = ax1.twinx()  \n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('accuracy', color=color) \n",
        "ax2.set_xlabel('epoch', color=color)\n",
        "ax2.plot( accuracy_list, color=color)\n",
        "ax2.tick_params(axis='y', color=color)\n",
        "fig.tight_layout()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OvSQTEGlqat"
      },
      "source": [
        "<h2>About the Authors:</h2>\n",
        " <a href=\\\"https://www.linkedin.com/in/joseph-s-50398b136/\\\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm8vxvpalqau"
      },
      "source": [
        "## Change Log\n",
        "\n",
        "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
        "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
        "| 2020-09-18        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TUc2_qdlqau"
      },
      "source": [
        "Copyright © 2019 <a href=\"cognitiveclass.ai\"> cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>\n"
      ]
    }
  ]
}